{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 5. Target Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T03:24:48.092720Z",
     "start_time": "2019-11-02T03:24:48.014557Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Modules\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Enable plotly offline plotting\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML, display\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "# Ignore sklearn warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# Init project path\n",
    "PROJECT_DIR = os.getcwd() + \"/../../\"\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T04:27:11.780802Z",
     "start_time": "2019-11-02T04:26:46.762619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-02 04:26:48,561 - INFO - [load data] done in 1.67 s\n",
      "2019-11-02 04:27:04,673 - INFO - [preprocessing] done in 16.11 s\n",
      "2019-11-02 04:27:04,732 - INFO - [fill missing data] done in 0.06 s\n",
      "2019-11-02 04:27:05,050 - INFO - [one hot encoding] done in 0.32 s\n",
      "2019-11-02 04:27:07,885 - INFO - [create dataframe for CV] done in 2.83 s\n",
      "2019-11-02 04:27:11,303 - INFO - [target encoding] done in 3.4 s\n",
      "2019-11-02 04:27:11,584 - INFO - [drop unused columns] done in 0.28 s\n",
      "2019-11-02 04:27:11,773 - INFO - [rename non-ascii cols] done in 0.18 s\n"
     ]
    }
   ],
   "source": [
    "from src.exp.common.setup import *\n",
    "from src.exp.common.load_data import load_data\n",
    "from src.exp.common.correct_invalid_data import correct_invalid_data\n",
    "from src.exp.common.preprocessing import preprocessing\n",
    "from src.exp.common.fill_missing_data import fill_missing_data\n",
    "from src.exp.common.one_hot_encoding import one_hot_encoding\n",
    "from src.exp.common.create_cv_df import create_cv_df\n",
    "from src.exp.common.target_encoding import target_encoding\n",
    "from src.exp.common.drop_unused_columns import drop_unused_columns\n",
    "from src.exp.common.rename_non_ascii_cols import rename_non_ascii_cols\n",
    "\n",
    "# Step 1. Load train.csv, test.csv\n",
    "with timer(\"load data\"):\n",
    "    train_df, test_df = load_data(DATA_DIR=DATA_DIR)\n",
    "    original_train_df, original_test_df = load_data(DATA_DIR=DATA_DIR)\n",
    "    train_df = correct_invalid_data(train_df)\n",
    "    original_train_df = correct_invalid_data(original_train_df)\n",
    "\n",
    "# Step 2. Preprocessing\n",
    "with timer(\"preprocessing\"):\n",
    "    train_df = preprocessing(df=train_df)\n",
    "    test_df = preprocessing(df=test_df)\n",
    "\n",
    "with timer(\"fill missing data\"):\n",
    "    for col_name in [\"direction\", \"material\", \"layout\"]:\n",
    "        train_df = fill_missing_data(\n",
    "            df=train_df, col_name=col_name, method=\"most_frequent\"\n",
    "        )\n",
    "        test_df = fill_missing_data(\n",
    "            df=test_df, col_name=col_name, method=\"most_frequent\"\n",
    "        )\n",
    "\n",
    "# Step 3. Feature Engineering\n",
    "\n",
    "# Step 4. One-Hot Encoding\n",
    "with timer(\"one hot encoding\"):\n",
    "    for col_name in [\"direction\", \"layout\", \"material\"]:\n",
    "        train_df = one_hot_encoding(df=train_df, col_name=col_name)\n",
    "        test_df = one_hot_encoding(df=test_df, col_name=col_name)\n",
    "    \n",
    "# Step 5. Create dataframe for CV\n",
    "with timer(\"create dataframe for CV\"):\n",
    "    cv_df = create_cv_df(n_splits=N_FOLDS, random_state=SEED, train_df=train_df)\n",
    "\n",
    "# Step 6. Target Encoding\n",
    "with timer(\"target encoding\"):\n",
    "    col_names = [\"address_1\", \"address_1_2\"]\n",
    "    methods = {\"mean\": np.mean, \"median\": np.median}\n",
    "\n",
    "    cv_df_tmp = cv_df.copy()\n",
    "    cv_df = pd.DataFrame()\n",
    "    for n_fold in cv_df_tmp[\"n_fold\"].unique():\n",
    "        tr_df = cv_df_tmp.query(\"n_fold == {} and data_type == '{}'\".format(n_fold, \"train\"))\n",
    "        te_df = cv_df_tmp.query(\"n_fold == {} and data_type == '{}'\".format(n_fold, \"val\"))\n",
    "        for col_name in col_names:\n",
    "            tr_df, te_df = target_encoding(\n",
    "                tr_df=tr_df, te_df=te_df, col_name=col_name, methods=methods\n",
    "            )\n",
    "        cv_df = pd.concat([cv_df, tr_df, te_df])\n",
    "\n",
    "    for col_name in col_names:\n",
    "        train_df, test_df = target_encoding(\n",
    "            tr_df=train_df, te_df=test_df, col_name=col_name, methods=methods\n",
    "        )\n",
    "\n",
    "# Step 7. Drop unused columns\n",
    "with timer(\"drop unused columns\"):\n",
    "    train_df = drop_unused_columns(df=train_df)\n",
    "    test_df = drop_unused_columns(df=test_df)\n",
    "    cv_df = drop_unused_columns(df=cv_df)\n",
    "\n",
    "# Step 8. Rename non-ascii columns as lightGBM doesn't support them.\n",
    "with timer(\"rename non-ascii cols\"):\n",
    "    train_df = rename_non_ascii_cols(df=train_df)\n",
    "    cv_df = rename_non_ascii_cols(df=cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T04:27:11.911168Z",
     "start_time": "2019-11-02T04:27:11.784719Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_df[\"target_address_1_2_mean\"] = cv_df[\"target_address_1_2_mean\"].fillna(cv_df[\"target_address_1_mean\"])\n",
    "cv_df[\"target_address_1_2_median\"] = cv_df[\"target_address_1_2_median\"].fillna(cv_df[\"target_address_1_median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T04:27:11.982667Z",
     "start_time": "2019-11-02T04:27:11.914645Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {\n",
    "    \"task\": \"train\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": {\"l2\"},\n",
    "    \"num_leaves\": 1000,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 20,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "# xgb parameters\n",
    "xgb_params = {\"objective\": \"reg:squarederror\", \"eval_metric\": \"rmse\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T04:27:48.525391Z",
     "start_time": "2019-11-02T04:27:11.987695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- linearRegression ----------------\n",
      "n_fold: 0 Score: 23273.53680897503\n",
      "n_fold: 1 Score: 24062.868121736898\n",
      "n_fold: 2 Score: 25379.067101171648\n",
      "n_fold: 3 Score: 30143.79641843235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-02 04:27:13,996 - INFO - [cv with linear regression] done in 1.93 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_fold: 4 Score: 23211.032628115423\n",
      "---------------- linearRegression  END ----------------\n",
      "\n",
      "---------------- xgboost ----------------\n",
      "n_fold: 0 Score: 18863.39807657058\n",
      "n_fold: 1 Score: 15022.565533978819\n",
      "n_fold: 2 Score: 16850.679528791912\n",
      "n_fold: 3 Score: 23211.523725406394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-02 04:27:33,995 - INFO - [cv with xgboost] done in 19.99 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_fold: 4 Score: 18590.426580973\n",
      "---------------- xgboost  END ----------------\n",
      "\n",
      "---------------- lightgbm ----------------\n",
      "n_fold: 0 Score: 19162.298338085253\n",
      "n_fold: 1 Score: 16981.23522445959\n",
      "n_fold: 2 Score: 18451.199662966595\n",
      "n_fold: 3 Score: 24710.5588001783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-02 04:27:48,518 - INFO - [cv with lightgbm] done in 14.52 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_fold: 4 Score: 17948.662646566958\n",
      "---------------- lightgbm  END ----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5. Cross Validation\n",
    "from src.exp.common.cv import cv\n",
    "\n",
    "with timer(\"cv with linear regression\"):\n",
    "    lr_result, scores = cv(\n",
    "        cv_df=cv_df, model_name=\"linearRegression\", params=None\n",
    "    )\n",
    "with timer(\"cv with xgboost\"):\n",
    "    xgb_result, scores = cv(\n",
    "        cv_df=cv_df, model_name=\"xgboost\", params=xgb_params\n",
    "    )\n",
    "with timer(\"cv with lightgbm\"):\n",
    "    lgb_result, scores = cv(\n",
    "        cv_df=cv_df, model_name=\"lightgbm\", params=lgb_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T04:27:51.454348Z",
     "start_time": "2019-11-02T04:27:48.528841Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e5d807efec48efb7ff4f3ada1566ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='n_fold', options=(0, 1, 2, 3, 4), value=0), Output()), _dom_classe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.exp.common.plot_result import plot_result\n",
    "\n",
    "\n",
    "@interact(n_fold=list(range(N_FOLDS)))\n",
    "def plot_results(n_fold):\n",
    "    plot_result(original_train_df, lr_result, n_fold, \"lr\")\n",
    "    plot_result(original_train_df, xgb_result, n_fold, \"xgb\")\n",
    "    plot_result(original_train_df, lgb_result, n_fold, \"lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "403.722px",
    "left": "948.023px",
    "right": "20px",
    "top": "56.9545px",
    "width": "344.162px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
